#Estimation of the mAb glycoprofile based on NSD experimental data from the B&B paper
#The model will be trained in 4 experiments (control(P1), 10G(P2), 10G20U(P4), 50G5U(P5))
#The model will be tuned (number of neurons) to simulate the 10G5U experiment(P3)

#HL1=24
#HL2=10
import numpy as np

def sigmoid(x):
    return 1/(1+np.exp(-x))

def sigmoid_der(x):
    return sigmoid(x)*(1-sigmoid(x))

error = np.zeros([41,41])

epochs = 20000

for i in range(0, 41):
    print (i)
    for j in range(0, 41):

        np.random.seed(0)
        feature_set = np.array([[0.320486562922805,	0.0957281487210295,	0.5,	0.107663705019213,	0.446858900433255,	0.0501527304582096,	0.225319828973266,	0.279220030006542,	0.0149528966951536,	0.0214701282755559,	0.061073158760873,	0.0212726475917873],
        [0.281737431691896,	0.140082611619834,	0.436647321798297,	0.0959545469530093,	0.401737843055916,	0.0472132734347633,	0.255312142485699,	0.276775326804483,	0.0136991834833688,	0.0353750399630368,	0.0620963823852554,	0.0354171910581337],
        [0.441510210845201,	0.368415303673667,	0.496106212304413,	0.114501888055843,	0.487281235328437,	0.0694528977670322,	0.332317579009611,	0.29153085684548,	0.123830545330073,	0.117230040259216,	0.0757487216305336,	0.108412540110309],
        [0.480056520471347,	0.5,	0.490883107231713,	0.103459646742909,	0.462385293978455,	0.0665173942609436,	0.32159035108743,	0.227095465305508,	0.11240003345345,	0.149255804137502,	0.0824038766458398,	0.15640419913987],
        [0.282343460635899,	0.118235252154003,	0.43492266750692,	0.0970697048422539,	0.39221653086499,	0.0427549193023729,	0.309463018635739,	0.39630383869301,	0.0551999652433187,	0.0198591338745978,	0.0549956915783058,	0.02066713998748],
        [0.39117173031795,	0.243526907000548,	0.436161832311535,	0.0962885497559727,	0.446108265432495,	0.047751500782836,	0.340461942497785,	0.5,	0.0658731375060604,	0.0309856326780288,	0.0636258707069915,	0.0307984435989251],
        [0.5,	0.368818561847093,	0.43740099711615,	0.0955073946696915,	0.5,	0.0527480822632991,	0.386159621499353,	0.393204313035282,	0.105549724256637,	0.0702612486202573,	0.0373178707915399,	0.0685298368559572],
        [0.127678909627886,	0.0581656787717452,	0.226604501721371,	0.5,	0.46883376282812,	0.5,	0.293608960019112,	0.200029108285271,	0.368310385844743,	0.156369552489502,	0.5,	0.163245440866554],
        [0.169283483687934,	0.0779418925509932,	0.285126783861237,	0.268373642524276,	0.339807840380493,	0.215202963430149,	0.256506344039572,	0.21919383858401,	0.173877946729333,	0.0507205015515942,	0.284256793733227,	0.0524831663993643],
        [0.219651768791483,	0.108298505214601,	0.288197053596886,	0.267607842505991,	0.393047325801961,	0.251117666172876,	0.367686080316996,	0.379559578508845,	0.229729891033818,	0.107467909088639,	0.433952742065862,	0.110978007116357],
        [0.270020053895032,	0.138655117878209,	0.291267323332535,	0.266842042487705,	0.446286811223429,	0.287032368915603,	0.442197889361273,	0.363736912294015,	0.459849165693358,	0.395918450683489,	0.434164210918897,	0.408648759298455]])
        
        labels = np.array([[0.064129641,	0.060006061,	0.057963183,	0.060578699,	0.04801502,	0.056749127,	0.05056766,	0.03729378,	0.041926173,	0.03140784,	0.036667007],
        [0.524051425,	0.515046527,	0.520968923,	0.536518635,	0.4891363,	0.484554236,	0.475295968,	0.473100902,	0.418039198,	0.443201672,	0.41417279],
        [0.346344857,	0.363193137,	0.340245869,	0.342065591,	0.3982028,	0.380502521,	0.39632325,	0.391301779,	0.418565498,	0.41475993,	0.417065795],
        [0.004505264,	0.004505264,	0.00285,	0.004378582,	0.004378582,	0.004378582,	0.00486606,	0.00486606,	0.008383955,	0.00375555,	0.006653057],
        [0.046663351,	0.050148329,	0.04065236,	0.047542788,	0.05807403,	0.034639551,	0.065576103,	0.072536927,	0.079412147,	0.074366598,	0.083883881],
        [0.018810726,	0.007100683,	0.034616107,	0.008915705,	0.00657189,	0.043554566,	0.007370959,	0.044413505,	0.029021069,	0.03011102,	0.0345]]).T
        
#ANN parameters
        wh1 = np.random.rand(len(feature_set[0]),i)
        wh2 = np.random.rand(i, j)
        wo  = np.random.rand(j, len(labels[0]))
        lr = 0.5

        #print (wh1) #it was silenced in order to save some time during optimization

        for epoch in range(epochs):
            #FEEDFORWARD
            zh1 = np.dot(feature_set, wh1)
            ah1 = sigmoid(zh1)

            zh2 = np.dot(ah1, wh2)
            ah2 = sigmoid(zh2)
            
            zo = np.dot(ah2, wo)
            ao = sigmoid(zo)

#ANN error
            error_output = ((1/2)*(np.power((ao - labels), 2)))

#Part1: from HL2 to the Output
            dcost_dao = ao - labels
            dao_dzo   = sigmoid_der(zo)
            dzo_dwo   = ah2
            dcost_dwo = np.dot(dzo_dwo.T, dcost_dao*dao_dzo)
#Part2: from HL1 to HL2
            dcost_dzo = dcost_dao*dao_dzo
            dzo_dah2  = wo
            dcost_dah2 = np.dot(dcost_dzo, dzo_dah2.T)
            dah2_dzh2 = sigmoid_der(zh2)
            dzh2_dwh2 = ah1
            dcost_dwh2 = np.dot(dzh2_dwh2.T, dah2_dzh2*dcost_dah2)
#Part2: from the Input to HL1
            dcost_dzh2 = dcost_dah2*dah2_dzh2
            dzh2_dah1  = wh2
            dcost_dah1 = np.dot(dcost_dzh2, dzh2_dah1.T)
            dah1_dzh1 = sigmoid_der(zh1)
            dzh1_dwh1 = feature_set
            dcost_dwh1 = np.dot(dzh1_dwh1.T, dah1_dzh1*dcost_dah1)
#update weights
            wo  -= lr*dcost_dwo
            wh2 -= lr*dcost_dwh2
            wh1 -= lr*dcost_dwh1

        single_point = np.array([[0.189891758455431,	0.0646694920178832,	0.290268364557683,	0.299184671529705,	0.365827130713872,	0.224510818559532,	0.273245762925077,	0.180864377986531,	0.141680158534829,	0.0595338250996023,	0.26902073040964,	0.0606662983223195],
        [0.206006269423947,	0.0821124663955874,	0.282267107446671,	0.3264770722569,	0.388877730010652,	0.311035206994327,	0.31809010066405,	0.263940624364299,	0.232007244495352,	0.148029275494096,	0.438846633387714,	0.149528820382385],
        [0.266418181470491,	0.179859829804013,	0.265599898666185,	0.256886644770487,	0.350313012466841,	0.264874066714283,	0.287061438504015,	0.260797437809553,	0.333709504557383,	0.330729227013243,	0.42463150212162,	0.322198834166374],
        [0.30684518770035,	0.239377910408411,	0.28520369239926,	0.242393294584306,	0.377129434181599,	0.258852225948944,	0.314013352406707,	0.115861477261858,	0.5,	0.5,	0.435959721935278,	0.5]])
        
        #results
        resulth1 = sigmoid(np.dot(single_point, wh1))
        resulto1 = sigmoid(np.dot(resulth1, wh2))
        resulto2 = sigmoid(np.dot(resulto1, wo))

        experimental_results = np.array([[0.0521049,	0.049748503,	0.051655478,	0.047616816],
        [0.447665056,	0.418781566,	0.46057572,	0.397471592],
        [0.415573959,	0.418381974,	0.407668677,	0.438894841],
        [0.007361399,	0.008429525,	0.007509387,	0.00345],
        [0.072348746,	0.078123761,	0.069063602,	0.089123178],
        [0.00494594,	0.0264,	0.003527136,	0.021875569]]).T

        error_table = abs(resulto2 - experimental_results)
        
        error[i,j] = error_table.sum()

for i in range(0,41):
    for j in range(0,41):
        if error[i,j] == error.min():
            x = i
            y = j

print ("The minimum error is found in the following coordinates (number of nodes): x=", x, ", y=", y)
print ("The error of the optimized NN is: ", error[x,y])
print ("The optimum nodes combination therefore is: HL1: ", x, ", HL2: ", y)


print (error)

